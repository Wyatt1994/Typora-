https://mp.weixin.qq.com/s/y3CheyPMJpLpD3pB3lTT9g

![è¿éåå¾çæè¿°](https://img-blog.csdn.net/20171027100748177?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMzEyMzYzNQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

ActiveMQ支持JMS规范，RabbitMQ支持AMQP规范

**jms** 
java消息服务(Java Message Service)即JMS，是一个Java平台中关于面向消息中间件的api，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信 

![è¿éåå¾çæè¿°](https://img-blog.csdn.net/20171027102839142?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMzEyMzYzNQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

**AMQP** 

AMQP(advanced message queuing protocol)是一个提供统一消息服务的应用层标准协议，基于此协议的客户端与消息中间件可传递消息，**并不受客户端/中间件不同产品，不同开发语言等条件的限制** 



#### 消息中间件详解

https://www.jianshu.com/p/1ff7082c95df

**2.消息中间件的组成**

**2.1 Broker**

消息服务器，作为server提供消息核心服务

**2.2 Producer**

消息生产者，业务的发起方，负责生产消息传输给broker，

**2.3 Consumer**

消息消费者，业务的处理方，负责从broker获取消息并进行业务逻辑处理

**2.4 Topic**

主题，发布订阅模式下的消息统一汇集地，不同生产者向topic发送消息，由MQ服务器分发到不同的订阅者，实现消息的广播

**2.5 Queue**

队列，PTP模式下，特定生产者向特定queue发送消息，消费者订阅特定的queue完成指定消息的接收

**2.6 Message**

消息体，根据不同通信协议定义的固定格式进行编码的数据包，来封装业务数据，实现消息的传输

**3 消息中间件模式分类**

**3.1 点对点**

PTP点对点:使用**queue**作为通信载体



![img](https:////upload-images.jianshu.io/upload_images/15707376-fd13c9f0609720ed.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/928/format/webp)



说明：

消息生产者生产消息发送到queue中，然后消息消费者从queue中取出并且消费消息。

消息被消费以后，queue中不再存储，所以消息消费者不可能消费到已经被消费的消息。 Queue支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。

**3.2 发布/订阅**

Pub/Sub发布订阅（广播）：使用**topic**作为通信载体



![img](https:////upload-images.jianshu.io/upload_images/15707376-d7c2e67603b1520e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/946/format/webp)



说明：

消息生产者（发布）将消息发布到topic中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到topic的消息会被所有订阅者消费。

queue实现了负载均衡，将producer生产的消息发送到消息队列中，由多个消费者消费。但一个消息只能被一个消费者接受，当没有消费者可用时，这个消息会被保存直到有一个可用的消费者。

**topic实现了发布和订阅**，当你发布一个消息，所有订阅这个topic的服务都能得到这个消息，所以从1到N个订阅者都能得到一个**消息的拷贝。**

#### 异步消息队列的好处

**应用解耦**：有了MQ以后把一个人的事情分给了不同的人，分工合作所带来的好处是专业化，并行化，维护也更简单。比如用户买东西，下单后订单系统要通知库存系统，传统做法就是订单系统调用库存的接口，这样万一库存系统炸了，订单就会失败。因此采用消息队列，订单系统写入消息，库存系统监听消息，把订单系统和库存系统分开，应用解耦，维护更方便，安全性也更高。

**流量削峰**：比如秒杀场景，流量过大容易导致系统挂掉，加入消息队列后，一是可以用队列长度限制订单数量，二是可以异步读取队列，减轻后面服务器压力。



#### RabbitMQ

**RabbitMQ消息状态**

**4种状态包括：**

- alpha，消息的内容和索引都在内存中；
- beta，消息的内容在磁盘，索引在内存；
- gamma，消息的内容在磁盘，索引在磁盘和内存中都有；
- delta，消息的内容和索引都在磁盘。

**5个内部队列：**

- q1、q2、delta、q3、q4。
- q1和q4队列中只有alpha状态的消息；
- q2和q3包含beta和gamma状态的消息；
- delta队列是消息按序存盘后的一种逻辑队列，只有delta状态的消息，所以delta队列并不在内存中。
- ![img](https://img-blog.csdn.net/20180705160728360?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21haWhpbHRvbg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
- 
- ![a789e83e1de4d4dfa2233f9d87158ceb.jpg](https://s4.51cto.com/oss/201710/30/a789e83e1de4d4dfa2233f9d87158ceb.jpg)
- 

#### RabbitMQ消息重复消费

问题描述：

手动ACK时，如果消息已经消费过了但还没来得及发送ACK突然挂掉了，那么RabbitMQ会把消息重新投递给其他消费者导致消息重复消费。

解决办法：

消费者每次执行查询前，首先在DB（**Redis**）上查询任务的执行状态或者使用**map**（即使用future接口得到执行结果，有多个消费者的话可以使用**哈希法取模**，每条消息固定消费者）存放消息执行结果(根据消息的全局唯一id)，若处于「取消/失败/成功」则表示已经由其它消费者消费过，那么直接返回ACK状态码给MQ，将消息从MQ中移除；



#### RabbitMQ消息丢失

1. 如果客户端宕机导致消息丢失，RabbitMQ有ACK机制来解决。

2. 如果RabbitMQ本身宕机导致消息丢失，RabbitMQ提供了持久化机制，将内存中的消息持久化到硬盘上，即使重启RabbitMQ，消息也不会丢失。

3. 但是，仍然有一个非常短暂的时间窗口（RabbitMQ收到消息还没来得及存到硬盘上）会导致消息丢失，针对这种情况，可以设置RabbitMQ队列为持久化队列，这样消息和队列直接都是持久化的，但这样性能就低了。

4. 若是生产者将数据发送到rabbitmq的时候，可能数据就在半路给搞丢了，因为网络啥的问题。

   1）此时可以选择用**rabbitmq提供的事务功能**，就是生产者发送数据之前开启**rabbitmq事务**（channel.txSelect），然后发送消息，**如果消息没有成功被rabbitmq接收到，那么生产者会收到异常报错，此时就可以回滚事务**（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事务（channel.txCommit）。但是问题是，rabbitmq事务机制一搞，基本上**吞吐量会下来，因为太耗性能**。

   2）可以**开启confirm模式**，在生产者那里设置开启**confirm模式**之后，你每次写的消息都会**分配一个唯一的id，然后如果写入了rabbitmq中，rabbitmq会给你回传一个ack消息**，告诉你说这个消息ok了。如果rabbitmq没能处理这个消息，**会回调你一个nack接口**，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。

   **事务机制和cnofirm机制最大的不同在于**，事务机制是**同步**的，你提交一个事务之后会**阻塞**在那儿，但是confirm机制是**异步**的，你发送个消息之后就可以发送下一个消息，然后那个消息rabbitmq接收了之后会异步回调你一个接口通知你这个消息接收到了。

   **所以一般在生产者这块避免数据丢失，都是用confirm机制的**。

##### 四种交换机模式

1、Direct模式，发送者把消息先送到交换机，然后根据匹配的RouteKey从交换机到消息队列里。

2、Fanout模式，即广播订阅，只需**指定交换机名称**，向**所有的消费者**发布消息,但是只有消费者**将队列绑定到该路由器才能收到消息**，交换机把收到的消息送给**自己绑定的队列**。一个交换机可以绑定多个队列。

3、Topic模式（**跟Direct类似，只是主题模式routeKey是可以模糊匹配的**），即主题匹配订阅，除了**指定交换机，还需匹配routeKey**。可以当做相当于Fanout模式的条件限制版本，各个交换机绑定Queue的时候还要绑定感兴趣的RouteKey，发送者发消息的时候要带RouteKey，交换机把包含自己感兴趣的RouteKey的消息送给自己绑定的队列，一个消息可能被多个交换机同时处理

4、Header模式，用的很少。通过Header信息来匹配交换机和Queue，写起来太过复杂。



#### 消息的绝对顺序执行

注：添加到消息队列的顺序性由生产者保证

拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理

消息体通过hash分派到队列里，每个队列对应一个消费者，多分拆队列。 即**同一组的任务会被分配到同一个队列里**，每个队列只能有一个worker来消费

![img](https://upload-images.jianshu.io/upload_images/325120-0e517992c4a967ad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/358/format/webp)



**应用层解决方式：**

- **1.** 消息实体中增加：版本号 & 状态机 & msgid & parent_msgid，通过 parent_msgid 判断消息的顺序（需要全局存储，记录消息的执行状态）。
- **2.** “同步执行”：当一个消息执行完之后，再发布下一个消息。
- 

#### RabbitMQ

**并不是分布式消息队列**，它就是传统的消息队列，只不过提供了一些**集群、HA(High Availability, 高可用性) 的机制**而已，因为无论怎么玩儿，**RabbitMQ 一个 queue 的数据都是放在一个节点里（简单主从集群，保证高吞吐量）**的，**镜像集群（保证高可用性，避免单点故障）**下，也是每个节点都放这个 queue 的完整数据。

注：消费者消费时要自己实现Consumer接口方法即**回调接口，处理完毕才发送ACK**

#### **Kafka**

典型的Kafka体系架构包括若干Producer(可以是服务器日志，业务数据，页面前端产生的page view等等)，若干broker(Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高)，若干Consumer (Group)，以及一个Zookeeper集群。**Kafka通过Zookeeper管理集群配置，选举leader，以及在consumer group发生变化时进行rebalance**。Producer使用push(推)模式将消息发布到broker，Consumer使用pull(拉)模式从broker订阅并消费消息。



一个topic可以认为一个一类消息，每个topic将被分成多个partition，每个partition在存储层面是append log文件。任何发布到此partition的消息都会被追加到log文件的尾部，每条消息在文件中的位置称为offset(偏移量)，offset为一个long型的数字，它唯一标记一条消息。**每条消息都被append到partition中，是顺序写磁盘，因此效率非常高(经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证)**。



**1.天然的分布式消息队列**：由多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，**每个 partition 可以存在于不同的 broker** 上，**每个 partition 就放一部分数据。**一个 topic 的数据，是**分散放在多个机器上的，每个机器就放一部分数据**。

![img](https://upload-images.jianshu.io/upload_images/10089464-c7557f252f406db5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/712/format/webp)



**2.**Kafka 0.8 以后，提供了 **HA 机制（高可用性）**，就是 replica（复制品） 副本机制。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。**所有 replica 会选举一个 leader 出来**，那么**生产和消费都跟这个 leader 打交道**，然后其他 replica 就是 follower。写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。只能读写 leader？很简单，**要是你可以随意读写每个 follower，那么就要 care 数据一致性的问题**，系统复杂度太高，很容易出问题。**Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。**



![img](https:////upload-images.jianshu.io/upload_images/10089464-9046e9d49f2f2691.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/721/format/webp)

3.保证了**高可用性**。因为如果某个 broker 宕机了，那个 broker上面的 partition 在其他机器上都有副本的，如果这上面有某个 partition 的 leader，那么此时会从 follower 中**重新选举**一个新的 leader 出来，大家继续读写那个新的 leader 即可。这就有所谓的**高可用性**了。

**写数据**的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）

**消费**的时候，只会**从 leader 去读**，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。

![img](https://upload-images.jianshu.io/upload_images/10089464-9046e9d49f2f2691.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/721/format/webp)

