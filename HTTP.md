# HTTP

### 标准请求报文格式

HTTP请求报文由：**请求行+请求头+空白行+请求体**构成，为什么空白行是因为浏览器发送了一空白行来通知服务器，它已经结束了该头信息的发送

![1541581836462](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\1541581836462.png)

### Http和Https的区别

#### 区别

HTTPS和HTTP的区别主要如下：

　　1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。

　　2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。

　　3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。

　　4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。

# Https的通信过程

![1541582163191](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\1541582163191.png)

客户端在使用HTTPS方式与Web服务器通信时有以下几个步骤，如图所示。

　　（1）客户使用https的URL访问Web服务器，要求与Web服务器建立SSL连接。

　　（2）Web服务器收到客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端。

　　（3）客户端的浏览器与Web服务器开始协商SSL连接的安全等级，也就是信息加密的等级。

　　（4）客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。

　　（5）Web服务器利用自己的私钥解密出会话密钥。

　　（6）Web服务器利用会话密钥加密与客户端之间的通信。

**GET请求可传递的字符串长度有限，但据实际测试并不是固定的，而是因不同浏览器而异**。

# TCP滑动窗口和拥塞控制

https://www.cnblogs.com/woaiyy/p/3554182.html

### 滑动窗口

所谓滑动窗口协议：1. “窗口”对应的是一段**可以被发送者发送的字节序列**，其连续的范围称之为“窗口”；2. “滑动”则是指这段“允许发送的范围”是可以随着发送的过程而变化的，方式就是按顺序“滑动”。

1. TCP协议的两端分别为发送者A和接收者B，由于是**全双工协议**，因此A和B应该**分别维护**着一个独立的发送缓冲区和接收缓冲区，由于对等性（A发B收和B发A收），我们以A发送B接收的情况作为例子；
2. 发送窗口是发送缓存中的一部分，是可以被TCP协议发送的那部分，其实应用层需要发送的所有数据都被放进了发送者的发送缓冲区；
3. 发送窗口中相关的有四个概念：已发送并收到确认的数据（不再发送窗口和发送缓冲区之内）、**已发送但未收到确认的数据（位于发送窗口之中）**、**允许发送但尚未发送的数据（位于发送窗口之中）**以及发送窗口外发送缓冲区内暂时不允许发送的数据；
4. 每次成功发送数据之后，发送窗口就会在发送缓冲区中按顺序移动，将新的数据包含到窗口中准备发送；



**字节31-50为发送窗口**
![img](http://blog.chinaunix.net/attachment/201402/17/26275986_1392626885IL2q.png)
​     A发送11个字节后，发送窗口位置不变，B接收到了**乱序**的数据分组：
![img](http://blog.chinaunix.net/attachment/201402/17/26275986_1392627107R2FQ.png)
​      只有当A成功发送了数据，即发送的数据得到了B的确认之后，才会**移动滑动窗口**离开已发送的数据；同时B则确认连续的数据分组，**对于乱序的分组则先接收下来，避免网络重复传递**：
![img](http://blog.chinaunix.net/attachment/201402/17/26275986_13926272726XTE.png)

------

### 流量控制

**1.流量控制**

 所谓流量控制，主要是接收方传递信息给发送方，使其不要发送数据太快，是一种端到端的控制。主要的方式就是**返回的ACK中会包含自己的接收窗口的大小**，并且利用**大小**来控制发送方的数据发送：

![img](http://blog.chinaunix.net/attachment/201402/17/26275986_1392627535jeG5.png)

这里面涉及到一种情况，如果B已经告诉A自己的缓冲区已满，于是A停止发送数据；等待一段时间后，B的缓冲区出现了富余，于是给A发送报文告诉A我的rwnd（**接收窗口**）大小为400，但是这个报文不幸丢失了，于是就出现**A等待B的通知**||**B等待A发送数据的死锁状态**。为了处理这种问题，TCP引入了**持续计时器（Persistence timer）**，当A收到对方的零窗口通知时，就启用该计时器，时间到则发送一个1字节的**探测报文**，对方会在此时回应自身的接收窗口大小，如果结果仍未0，则**重设持续计时器，继续等待**。

2. **传递效率**
     一个显而易见的问题是：**单个发送字节单个确认，和窗口有一个空余即通知发送方发送一个字节，无疑增加了网络中的许多不必要的报文**（请想想为了一个字节数据而添加的40字节头部吧！），所以我们的原则是尽可能一次多发送几个字节，或者**窗口空余较多**的时候通知发送方一次发送多个字节。对于**前者**我们广泛使用Nagle算法，即：

     1. 若发送应用进程要把发送的数据逐个字节地送到TCP的发送缓存，则发送方就把**第一个数据字节**先发送出去，把后面的字节先缓存起来；

     2.  当发送方**收到第一个字节的确认**后（也得到了网络情况和对方的接收窗口大小），再把缓冲区的剩余字节组成合适大小的报文发送出去；

     3.  当到达的数据**已达到发送窗口大小的一半或已达到报文段的最大长度**时，就立即发送一个报文段；



        对于**后者**我们往往的做法是**让接收方等待一段时间**，**或者接收方获得足够的空间容纳一个报文段或者等到接受缓存有一半空闲的时候，再通知发送方发送数据**。

### 拥塞控制

 网络中的链路容量和交换结点中的缓存和处理机都有着工作的极限，当网络的需求超过它们的工作极限时，就出现了拥塞。拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。常用的方法就是：
1. **慢开始算法、拥塞避免算法**
2. **快重传、快恢复**
     一切的基础还是慢开始，这种方法的思路是这样的：
     -1. 发送方维持一个叫做“**拥塞窗口**”的变量，**该变量和接收端口共同决定了发送者的发送窗口；**
     -2. 当主机开始发送数据时，避免一下子将大量字节注入到网络，造成或者增加拥塞，选择发送一个1字节的**试探报文**；
     -3. 当收到第一个字节的数据的确认后，就发送2个字节的报文；
     -4. 若再次收到2个字节的确认，则发送4个字节，依次递增2的**指数级**；
     -5. 最后会达到一个提前预设的**“慢开始门限（图中为24）”**，比如24，即一次发送了24个分组，此时遵循下面的条件判定：
     *1. cwnd < ssthresh（图中为16）， 继续使用慢开始算法；
     *2. cwnd > ssthresh，停止使用慢开始算法，改用拥塞避免算法；
     *3. cwnd = ssthresh，既可以使用慢开始算法，也可以使用拥塞避免算法；
     -6. 所谓拥塞避免算法就是：每经过一个往返时间RTT就把**发送方的拥塞窗口+1**，即让拥塞窗口缓慢地增大，按照**线性**规律增长；
     -7. 当出现网络拥塞，比如**丢包**时，将慢开始门限设为原先的一半，然后将**cwnd设为1**，执行慢开始算法（较低的起点，指数级增长）；
     ![img](http://blog.chinaunix.net/attachment/201402/17/26275986_1392629245IG6b.png)

上述方法的目的是在拥塞发生时循序减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够的时间把队列中积压的分组处理完毕。**慢开始和拥塞控制算法常常作为一个整体使用**，而**快重传和快恢复**则是为了**减少因为拥塞导致的数据包丢失带来的重传时间，从而避免传递无用的数据到网络**。

**快重传**的机制是：

接受方每收到一个**失序的报文段**都立即发送重复确认，而不用等待自己发送报文段的时候才进行捎带确认
发送方在一连收到接受方**3个重复确认**之后，就会立即重传失序的报文段，而**不用等待计时器**结束之后再重传

-1. 接收方建立这样的机制，如果一个包丢失，则对后续的包继续发送针对该包的重传请求；
-2. 一旦发送方接收到**三个一样的确认**，就知道**该包之后**出现了错误，立刻重传该包；
-3. 此时发送方开始执行**“快恢复”**算法：

**快恢复**

与快重传算法进行配合，在收到3次重复确认时，**不必执行慢开始算法**(因为此时网络状况还行，要不然不会收到3次重复确认)，而是把**拥塞窗口减半**，并把阈值也减半之后执行拥塞避免算法。

*1. 慢开始门限减半；
*2. **cwnd设为慢开始门限减半后的数值**；
*3. 执行**拥塞避免算法**（高起点，线性增长）；
![img](http://blog.chinaunix.net/attachment/201402/17/26275986_1392629231ue0O.png)



# HTTP1.0和 HTTP1.1的区别

HTTP1.0默认短连接，可以长连接，但是需要设置header connection：keep_Alive
HTTP1.1默认长连接

# HTTP1.0， HTTP1.1和 HTTP2.0的区别

HTTP2.0支持分帧传输，**二进制传输数据**，更加安全快捷，而 HTTP1.0， HTTP1.1支持文本

HTTP2.0进行分帧并进行二进制编码封装传输。二进制协议解析更加高效，紧凑，错误更少

HTTP2.0实现**多路复用**，而非有序并阻塞的——只需一个连接即可实现并行，更加快捷

HTTP1.x主要是保证请求的有序，即一个连接一次只提交一个请求，由于请求有限制，过多就会导致阻塞。而HTTP2.0则**将HTTP消息被分解为独立的帧，而不破坏消息本身的语义，交错发出去，在另一端根据流标识符和首部将他们重新组装起来。通过流ID标记多个请求，实现多路传输，即一次发送多个请求，而无需严格有序。**

HTTP2.0**压缩header**



HTTP2.0支持服务“主动”给客户端缓存发送数据

服务器发送HTML后无需等待客户端解析而主动推送js,css和图片。

